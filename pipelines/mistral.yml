components:
  answer_builder:
    init_parameters:
      pattern: null
      reference_pattern: null
    type: haystack.components.builders.answer_builder.AnswerBuilder
  llm:
    init_parameters:
      generation_kwargs: {}
      model: mistral-nemo
      raw: false
      streaming_callback: null
      system_prompt: null
      template: null
      timeout: 120
      url: http://localhost:11434/api/generate
    type: haystack_integrations.components.generators.ollama.generator.OllamaGenerator
  prompt_builder:
    init_parameters:
      required_variables: null
      template: "\nGiven the following information from datasets, answer the question.\nIgnore your\
        \ own knowledge. If the answer is not clear suggest which dataset, that was provided in the context, might help answering the question. \n\nQuestion: {{query}}\n\nContext:\n{% for document in documents\
        \ %}\n    {{ document.content }}\n{% endfor %}\n\nAnswer:\n"
      variables: null
    type: haystack.components.builders.prompt_builder.PromptBuilder
  retriever:
    init_parameters:
      document_store:
        init_parameters:
          collection_name: eidc_datasets
          embedding_function: default
          persist_path: chroma-data
        type: haystack_integrations.document_stores.chroma.document_store.ChromaDocumentStore
      filters: null
      top_k: 5
    type: haystack_integrations.components.retrievers.chroma.retriever.ChromaQueryTextRetriever
connections:
- receiver: prompt_builder.documents
  sender: retriever.documents
- receiver: answer_builder.documents
  sender: retriever.documents
- receiver: llm.prompt
  sender: prompt_builder.prompt
- receiver: answer_builder.replies
  sender: llm.replies
max_loops_allowed: 100
metadata: {}
