components:
  answer_builder:
    init_parameters:
      pattern: null
      reference_pattern: null
    type: haystack.components.builders.answer_builder.AnswerBuilder
  llm:
    init_parameters:
      generation_kwargs:
        max_new_tokens: 100
        temperature: 0.9
      huggingface_pipeline_kwargs:
        device: cpu
        model: google/flan-t5-large
        task: text2text-generation
      stop_words: null
      streaming_callback: null
      token:
        env_vars:
        - HF_API_TOKEN
        strict: false
        type: env_var
    type: haystack.components.generators.hugging_face_local.HuggingFaceLocalGenerator
  prompt_builder:
    init_parameters:
      required_variables: null
      template: "\nGiven the following information, answer the question.\n\nQuestion:\
        \ {{query}}\n\nContext:\n{% for document in documents %}\n    {{ document.content\
        \ }}\n{% endfor %}\n\nAnswer:\n"
      variables: null
    type: haystack.components.builders.prompt_builder.PromptBuilder
  retriever:
    init_parameters:
      document_store:
        init_parameters:
          collection_name: eidc_datasets
          embedding_function: default
          persist_path: chroma-data
        type: haystack_integrations.document_stores.chroma.document_store.ChromaDocumentStore
      filters: null
      top_k: 3
    type: haystack_integrations.components.retrievers.chroma.retriever.ChromaQueryTextRetriever
connections:
- receiver: prompt_builder.documents
  sender: retriever.documents
- receiver: answer_builder.documents
  sender: retriever.documents
- receiver: llm.prompt
  sender: prompt_builder.prompt
- receiver: answer_builder.replies
  sender: llm.replies
max_loops_allowed: 100
metadata: {}
